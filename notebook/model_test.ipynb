{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:29:40.013567Z",
     "end_time": "2023-04-19T06:29:46.311016Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries and models\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42) prediction: Rank 1\n",
      "RandomForestClassifier(random_state=42) confidence: [0.   0.97 0.03 0.   0.   0.  ]\n",
      "RandomForestClassifier(random_state=42)'s minimum to maximum confidence value: [0.0, 0.97]\n",
      "--------------------------------\n",
      "GradientBoostingClassifier(random_state=42) prediction: Rank 1\n",
      "GradientBoostingClassifier(random_state=42) confidence: [2.85822227e-04 9.66735828e-01 3.13237365e-02 6.53863698e-04\n",
      " 9.36403671e-04 6.43462847e-05]\n",
      "GradientBoostingClassifier(random_state=42)'s minimum to maximum confidence value: [6.434628471815968e-05, 0.966735827630308]\n",
      "--------------------------------\n",
      "BaggingClassifier(n_estimators=100, random_state=42) prediction: Rank 1\n",
      "BaggingClassifier(n_estimators=100, random_state=42) confidence: [0. 1. 0. 0. 0. 0.]\n",
      "BaggingClassifier(n_estimators=100, random_state=42)'s minimum to maximum confidence value: [0.0, 1.0]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import data from csv\n",
    "# clean data\n",
    "df = (pd\n",
    "      .read_csv(\"data.csv\")\n",
    "      .drop(columns=[\"Timestamp\", \"Name\", \"Type\", \"Damage\"])\n",
    "      )\n",
    "\n",
    "# set features and target for models to train on and compare\n",
    "features = (df.drop(columns=[\"Rarity\"]))\n",
    "target = (df[\"Rarity\"])\n",
    "\n",
    "# compare models and see which one performs the best\n",
    "models = [RandomForestClassifier(n_estimators=100,\n",
    "                                 random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=100,\n",
    "                               random_state=42),\n",
    "    BaggingClassifier(n_estimators=100,\n",
    "                      random_state=42)]\n",
    "\n",
    "for model in models:\n",
    "    (model.fit(features,\n",
    "               target))\n",
    "\n",
    "    prediction, *_ = (model.predict(features))\n",
    "\n",
    "    confidence, *_ = (model.predict_proba(features))\n",
    "\n",
    "    min_max_confid = [min(confidence), max(confidence)]\n",
    "\n",
    "    print(f\"{model} prediction: {prediction}\")\n",
    "    print(f\"{model} confidence: {confidence}\")\n",
    "    print(f\"{model}'s minimum to maximum confidence value: {min_max_confid}\")\n",
    "    print(\"--------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T06:37:16.299983Z",
     "end_time": "2023-04-19T06:37:17.135866Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the Random Forest and Bagging Classifiers may show higher rates of confidence to their predictions, this\n",
    "confidence is misleading. If one compares the range of confidence values from lowest to highest, it becomes apparent\n",
    "that the Gradient Boosting Classifier is generalizing to data better than the Bagging and Random Forest Classifier.\n",
    "The same is observed when the values of each classifiers confidence values are compared. Bagging and Random Forest\n",
    "are either 1 or 0 which indicates it is either very confident or not at all, a major sign of overfitting. However, if\n",
    "the confidence values of the Gradient Booster are viewed, one can see they contain more variance of values than the\n",
    "Bagging and Random Forest.\n",
    "\n",
    "Therefore, the Gradient Boosting Classifier contains the best metrics to be the base model for the app's predictions\n",
    "on the monster data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
